
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Analytic Methods &#8212; Think Stats, 3rd edition</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap14';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Survival analysis" href="chap13.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Think Stats, 3rd edition</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Think Stats, 3rd edition
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chap00.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap01.html">Exploratory Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap02.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap03.html">Probability Mass Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap04.html">Cumulative Distribution Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap05.html">Modeling Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap06.html">Probability Density Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap07.html">Relationships between variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap08.html">Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap09.html">Hypothesis Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap10.html">Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap11.html">Multiple Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap12.html">Time Series Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap13.html">Survival analysis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Analytic Methods</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/AllenDowney/ThinkStats/tree/v3" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap14.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Analytic Methods</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normal-probability-plots">Normal Probability Plots</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normal-distributions">Normal Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-of-sample-means">Distribution of Sample Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-of-differences">Distribution of Differences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-limit-theorem">Central Limit Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-limits-of-the-central-limit-theorem">The Limits of the Central Limit Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applying-the-clt">Applying the CLT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-test">Correlation Test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-squared-test">Chi-squared Test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computation-and-analysis">Computation and Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-1">Exercise 14.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-2">Exercise 14.2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-3">Exercise 14.3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-4">Exercise 14.4</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>The third edition of <em>Think Stats</em> is available now from <a class="reference external" href="https://bookshop.org/a/98697/9781098190255">Bookshop.org</a> and <a class="reference external" href="https://amzn.to/42lmxwu">Amazon</a> (those are affiliate links). If you are enjoying the free, online version, consider <a class="reference external" href="https://buymeacoffee.com/allendowney">buying me a coffee</a>.</p>
<section id="analytic-methods">
<span id="chapter-analytic-methods"></span><h1>Analytic Methods<a class="headerlink" href="#analytic-methods" title="Link to this heading">#</a></h1>
<p>This book has focused on computational methods like simulation and resampling, but some of the problems we solved have analytic solutions that can be much faster to compute.</p>
<p>This chapter presents some of these methods and explains how they work.
At the end of the chapter, I make suggestions for integrating computational and analytic methods for data analysis.</p>
<p><a class="reference external" href="https://colab.research.google.com/github/AllenDowney/ThinkStats/blob/v3/nb/chap14.ipynb">Click here to run this notebook on Colab</a>.</p>
<div class="cell tag_remove-print tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">os.path</span><span class="w"> </span><span class="kn">import</span> <span class="n">basename</span><span class="p">,</span> <span class="n">exists</span>


<span class="k">def</span><span class="w"> </span><span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">urllib.request</span><span class="w"> </span><span class="kn">import</span> <span class="n">urlretrieve</span>

        <span class="n">local</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloaded &quot;</span> <span class="o">+</span> <span class="n">local</span><span class="p">)</span>


<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_remove-print tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">empiricaldist</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="o">%</span><span class="k">pip</span> install empiricaldist
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_remove-print tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">thinkstats</span><span class="w"> </span><span class="kn">import</span> <span class="n">decorate</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="normal-probability-plots">
<h2>Normal Probability Plots<a class="headerlink" href="#normal-probability-plots" title="Link to this heading">#</a></h2>
<p>Many analytic methods are based on the properties of the normal distribution, for two reasons: distributions of many measurements in the real world are well-approximated by normal distributions, and normal distributions have mathematical properties that make them useful for analysis.</p>
<p>To demonstrate the first point, we’ll look at some of the measurements in the penguin dataset.
Then we’ll explore the mathematical properties of the normal distribution.
Instructions for downloading the data are in the notebook for this chapter.</p>
<p>The following cell downloads the data from a repository created by Allison Horst.</p>
<p>Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. <a class="reference external" href="https://allisonhorst.github.io/palmerpenguins/">https://allisonhorst.github.io/palmerpenguins/</a>. doi: 10.5281/zenodo.3960218.</p>
<p>The data was collected as part of the research that led to this paper: Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081. <a class="reference external" href="https://doi.org/10.1371/journal.pone.0090081">https://doi.org/10.1371/journal.pone.0090081</a></p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download</span><span class="p">(</span>
    <span class="s2">&quot;https://raw.githubusercontent.com/allisonhorst/palmerpenguins/c19a904462482430170bfe2c718775ddb7dbb885/inst/extdata/penguins_raw.csv&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can read the data like this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;penguins_raw.csv&quot;</span><span class="p">)</span>
<span class="n">penguins</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(344, 17)
</pre></div>
</div>
</div>
</div>
<p>The dataset contains measurements from three penguin species.
For this example, we’ll select the Adélie penguins.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adelie</span> <span class="o">=</span> <span class="n">penguins</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;Species.str.startswith(&quot;Adelie&quot;)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">adelie</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>152
</pre></div>
</div>
</div>
</div>
<p>To see if penguin weights follow a normal distribution, we’ll compute the empirical CDF of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">empiricaldist</span><span class="w"> </span><span class="kn">import</span> <span class="n">Cdf</span>

<span class="n">weights</span> <span class="o">=</span> <span class="n">adelie</span><span class="p">[</span><span class="s2">&quot;Body Mass (g)&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">cdf_weights</span> <span class="o">=</span> <span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And we’ll compute the analytic CDF of a normal distribution with the same mean and standard deviation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">weights</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">m</span><span class="p">,</span> <span class="n">s</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(np.float64(3700.662251655629), np.float64(458.5661259101348))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="n">dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mf">3.5</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="n">m</span> <span class="o">+</span> <span class="mf">3.5</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">qs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s what the CDF of the data looks like compared to the normal model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_options</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">qs</span><span class="p">,</span> <span class="n">ps</span><span class="p">,</span> <span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">cdf_weights</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9a8e665b64947ce1df5c9f8f7bde385b1fbfeff8d4d5872fbf739f23334e2197.png" src="_images/9a8e665b64947ce1df5c9f8f7bde385b1fbfeff8d4d5872fbf739f23334e2197.png" />
</div>
</div>
<p>The normal distribution might be a good enough model of this data, but it’s certainly not a perfect fit.</p>
<p>In general, plotting the CDF of the data and the CDF of a model is a good way to evaluate how well the model fits the data.
But one drawback of this method is that it depends on how well we estimate the parameters of the model – in this example, the mean and standard deviation.</p>
<p>An alternative is a <strong>normal probability plot</strong>, which does not depend on our ability to estimate parameters.
In a normal probability plot the <span class="math notranslate nohighlight">\(y\)</span> values are the sorted measurements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And the <span class="math notranslate nohighlight">\(x\)</span> values are the corresponding percentiles of a normal distribution, computed using the <code class="docutils literal notranslate"><span class="pre">ppf</span></code> method of the <code class="docutils literal notranslate"><span class="pre">norm</span></code> object, which computes the “percent point function”, which is the inverse CDF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If the measurements are actually drawn from a normal distribution, the <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(x\)</span> values should fall on a straight line.
To see how well they do, we can use <code class="docutils literal notranslate"><span class="pre">linregress</span></code> to fit a line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">linregress</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">intercept</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">slope</span>

<span class="n">fit_xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">fit_ys</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">fit_xs</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows the <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> values along with the fitted line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fit_xs</span><span class="p">,</span> <span class="n">fit_ys</span><span class="p">,</span> <span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Standard normal&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Body mass (g)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ee75bd9cc7810d5af27c91f274b525a5360c747772232f8e1cda9fd37d207875.png" src="_images/ee75bd9cc7810d5af27c91f274b525a5360c747772232f8e1cda9fd37d207875.png" />
</div>
</div>
<p>The normal probability plot is not a perfectly straight line, which indicates that the normal distribution is not a perfect model for this data.</p>
<p>One reason is that the dataset includes male and female penguins, and the two groups have different means – let’s see what happens if we plot the groups separately.
The following function encapsulates the steps we used to make a normal probability plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">normal_probability_plot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Makes a normal probability plot with a fitted line.&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="n">intercept</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">intercept</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">slope</span>

    <span class="n">fit_xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">fit_ys</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">fit_xs</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fit_xs</span><span class="p">,</span> <span class="n">fit_ys</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
    <span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Standard normal&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s what the results look like for male and female penguins separately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grouped</span> <span class="o">=</span> <span class="n">adelie</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Sex&quot;</span><span class="p">)</span>

<span class="n">weights_male</span> <span class="o">=</span> <span class="n">grouped</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;MALE&quot;</span><span class="p">)[</span><span class="s2">&quot;Body Mass (g)&quot;</span><span class="p">]</span>
<span class="n">normal_probability_plot</span><span class="p">(</span><span class="n">weights_male</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Male&quot;</span><span class="p">)</span>

<span class="n">weights_female</span> <span class="o">=</span> <span class="n">grouped</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;FEMALE&quot;</span><span class="p">)[</span><span class="s2">&quot;Body Mass (g)&quot;</span><span class="p">]</span>
<span class="n">normal_probability_plot</span><span class="p">(</span><span class="n">weights_female</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Female&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Weight (g)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08b4e496844a147578d0273f68610e8a9cb0e2ed5d4ad465e5e3c2bba9fe6c46.png" src="_images/08b4e496844a147578d0273f68610e8a9cb0e2ed5d4ad465e5e3c2bba9fe6c46.png" />
</div>
</div>
<p>The normal probability plots for both groups are close to a straight line, which indicates that the distributions of weight follow normal distributions.
When we put the groups together, the distribution of their weights is a mixture of two normal distributions with different means – and a mixture like that is not always well modeled by a normal distribution.</p>
<p>Now let’s consider some of the mathematical properties of normal distributions that make them so useful for analysis.</p>
</section>
<section id="normal-distributions">
<h2>Normal Distributions<a class="headerlink" href="#normal-distributions" title="Link to this heading">#</a></h2>
<p>The following class defines an object that represents a normal distribution.
It contains as attributes the parameters <code class="docutils literal notranslate"><span class="pre">mu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma2</span></code>, which represent the mean and variance of the distribution.
The name <code class="docutils literal notranslate"><span class="pre">sigma2</span></code> is a reminder that variance is the square of the standard deviation, which is usually denoted <code class="docutils literal notranslate"><span class="pre">sigma</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Normal</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Represents a Normal distribution&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Make a Normal object.</span>

<span class="sd">        mu: mean</span>
<span class="sd">        sigma2: variance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span> <span class="o">=</span> <span class="n">sigma2</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a string representation.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Normal(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="si">}</span><span class="s2">)&quot;</span>

    <span class="fm">__str__</span> <span class="o">=</span> <span class="fm">__repr__</span>
</pre></div>
</div>
</div>
</div>
<p>As an example, we’ll create a <code class="docutils literal notranslate"><span class="pre">Normal</span></code> object that represents a normal distribution with the same mean and variance as the weights of the male penguins.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">weights_male</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">weights_male</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">dist_male</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dist_male</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal(4043.4931506849316, 120278.25342465754)
</pre></div>
</div>
</div>
</div>
<p>And another <code class="docutils literal notranslate"><span class="pre">Normal</span></code> object with the same mean and variance as the weights of the female penguins.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">weights_female</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">weights_female</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">dist_female</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dist_female</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal(3368.8356164383563, 72565.63926940637)
</pre></div>
</div>
</div>
</div>
<p>Next we’ll add a method to the <code class="docutils literal notranslate"><span class="pre">Normal</span></code> class that generates a random sample from a normal distribution.
To add methods to an existing class, we’ll use a Jupyter magic command, <code class="docutils literal notranslate"><span class="pre">add_method_to</span></code>, which is defined in the <code class="docutils literal notranslate"><span class="pre">thinkstats</span></code> module.
This command is not part of Python – it only works in Jupyter notebooks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def sample(self, n):
    &quot;&quot;&quot;Generate a random sample from this distribution.&quot;&quot;&quot;
    sigma = np.sqrt(self.sigma2)
    return np.random.normal(self.mu, sigma, n)
</pre></div>
</div>
</div>
</div>
<p>We’ll use <code class="docutils literal notranslate"><span class="pre">sample</span></code> to demonstrate the first useful property of a normal distribution: if you draw values from two normal distributions and add them, the distribution of the sum is also normal.</p>
<p>As an example, we’ll generate samples from the <code class="docutils literal notranslate"><span class="pre">Normal</span></code> objects we just made, add them together, and make a normal probability plot of the sums.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_sum</span> <span class="o">=</span> <span class="n">dist_male</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> <span class="o">+</span> <span class="n">dist_female</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">normal_probability_plot</span><span class="p">(</span><span class="n">sample_sum</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Total weight (g)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/33b567cbcfadb8b65eac37a8651c71cadf7ba8050819c06189d16430ccc37478.png" src="_images/33b567cbcfadb8b65eac37a8651c71cadf7ba8050819c06189d16430ccc37478.png" />
</div>
</div>
<p>The normal probability plot looks like a straight line, which indicates that the sums follow a normal distribution.
And that’s not all – if we know the parameters of the two distributions, we can compute the parameters of the distribution of the sum.
The following method shows how.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def __add__(self, other):
    &quot;&quot;&quot;Distribution of the sum of two normal distributions.&quot;&quot;&quot;
    return Normal(self.mu + other.mu, self.sigma2 + other.sigma2)
</pre></div>
</div>
</div>
</div>
<p>In the distribution of the sum, the mean is the sum of the means and the variance is the sum of the variances.
Now that we’ve defined the special method <code class="docutils literal notranslate"><span class="pre">__add__</span></code>, we can use the <code class="docutils literal notranslate"><span class="pre">+</span></code> operator to “add” two distributions – that is, to compute the distribution of their sum.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_sum</span> <span class="o">=</span> <span class="n">dist_male</span> <span class="o">+</span> <span class="n">dist_female</span>
<span class="n">dist_sum</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal(7412.328767123288, 192843.8926940639)
</pre></div>
</div>
</div>
</div>
<p>To confirm that this result is correct, we’ll use the following method, which plots the analytic CDF of a normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def plot_cdf(self, n_sigmas=3.5, **options):
    &quot;&quot;&quot;Plot the CDF of this distribution.&quot;&quot;&quot;
    mu, sigma = self.mu, np.sqrt(self.sigma2)
    low, high = mu - n_sigmas * sigma, mu + n_sigmas * sigma
    xs = np.linspace(low, high, 101)
    ys = norm.cdf(xs, mu, sigma)
    plt.plot(xs, ys, **options)
</pre></div>
</div>
</div>
</div>
<p>Here’s the result along with the empirical CDF of the sum of the random samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_sum</span><span class="o">.</span><span class="n">plot_cdf</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">sample_sum</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Total weight (g)&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/735bf59b3c32e52a9510e4cd08aa8a167823e52e9fedda2778932a3b80014ab5.png" src="_images/735bf59b3c32e52a9510e4cd08aa8a167823e52e9fedda2778932a3b80014ab5.png" />
</div>
</div>
<p>It looks like the parameters we computed are correct, which confirms that we can add two normal distributions by adding their means and variances.</p>
<p>As a corollary, if we generate <code class="docutils literal notranslate"><span class="pre">n</span></code> values from a normal distribution and add them up, the distribution of the sum is also a normal distribution.
To demonstrate, we’ll start by generating 73 values from the distribution of male weights and adding them up.
The following loop does that 1001 times, so the result is a sample from the distribution of sums.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights_male</span><span class="p">)</span>
<span class="n">sample_sums_male</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist_male</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
<span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>73
</pre></div>
</div>
</div>
</div>
<p>The following method makes a <code class="docutils literal notranslate"><span class="pre">Normal</span></code> object that represents the distribution of the sums.
To compute the parameters, we multiply both the mean and variance by <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def sum(self, n):
    &quot;&quot;&quot;Return the distribution of the sum of n values.&quot;&quot;&quot;
    return Normal(n * self.mu, n * self.sigma2)
</pre></div>
</div>
</div>
</div>
<p>Here’s the distribution of the sum of <code class="docutils literal notranslate"><span class="pre">n</span></code> weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_sums_male</span> <span class="o">=</span> <span class="n">dist_male</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And here’s how it compares to the empirical distribution of the random sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_sums_male</span><span class="o">.</span><span class="n">plot_cdf</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">sample_sums_male</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Total weights (g)&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6c835d9609c5a715253f46fd2a9d60deadda0df552e1532d4ae1b5c4da9ef7b1.png" src="_images/6c835d9609c5a715253f46fd2a9d60deadda0df552e1532d4ae1b5c4da9ef7b1.png" />
</div>
</div>
<p>The analytic distribution fits the distribution of the sample, which confirms that the <code class="docutils literal notranslate"><span class="pre">sum</span></code> method is correct.
So if we collect a sample of <code class="docutils literal notranslate"><span class="pre">n</span></code> measurements, we can compute the distribution of their sum.</p>
</section>
<section id="distribution-of-sample-means">
<h2>Distribution of Sample Means<a class="headerlink" href="#distribution-of-sample-means" title="Link to this heading">#</a></h2>
<p>If we can compute the distribution of a sample sum, we can also compute the distribution of a sample mean.
To do that, we’ll use a third property of a normal distribution: if we multiply or divide by a constant, the result is a normal distribution.
The following methods show how we compute the parameters of the distribution of a product or quotient.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def __mul__(self, factor):
    &quot;&quot;&quot;Multiplies by a scalar.&quot;&quot;&quot;
    return Normal(factor * self.mu, factor**2 * self.sigma2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def __truediv__(self, factor):
    &quot;&quot;&quot;Divides by a scalar.&quot;&quot;&quot;
    return self * (1 / factor)
</pre></div>
</div>
</div>
</div>
<p>To compute the distribution of the product we multiply the mean by <code class="docutils literal notranslate"><span class="pre">factor</span></code> and the variance by the square of <code class="docutils literal notranslate"><span class="pre">factor</span></code>.
We can use this property to compute the distribution of the sample means.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_mean_male</span> <span class="o">=</span> <span class="n">dist_sums_male</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>
</div>
</div>
</div>
<p>To see if the result is correct, we’ll also compute the means of the random samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_means_male</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sample_sums_male</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>
</div>
</div>
</div>
<p>And compare the normal model to the empirical CDF of the sample means.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_mean_male</span><span class="o">.</span><span class="n">plot_cdf</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">sample_means_male</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Average weight (g)&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7d88dfb12c211ddbfd036362ac882a0b5e5036a574f1c85b5564ca4c0c6f7cb2.png" src="_images/7d88dfb12c211ddbfd036362ac882a0b5e5036a574f1c85b5564ca4c0c6f7cb2.png" />
</div>
</div>
<p>The model and the simulation results agree, which shows that we can compute the distribution of the sample means analytically – which is very fast, compared to resampling.</p>
<p>Now that we know the sampling distribution of the mean, we can use it to compute the standard error, which is the standard deviation of the sampling distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">standard_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dist_mean_male</span><span class="o">.</span><span class="n">sigma2</span><span class="p">)</span>
<span class="n">standard_error</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(40.591222045992765)
</pre></div>
</div>
</div>
</div>
<p>This result suggests a shortcut we can use to compute the standard error directly, without computing the sampling distribution.
In the sequence of steps we followed, we multiplied the variance by <code class="docutils literal notranslate"><span class="pre">n</span></code> and then divided by <code class="docutils literal notranslate"><span class="pre">n**2</span></code> – the net effect was to divide the variance by <code class="docutils literal notranslate"><span class="pre">n</span></code>, which means we divided the standard deviation by the square root of <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
<p>So we can compute the standard error of the sample mean like this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">standard_error</span> <span class="o">=</span> <span class="n">weights_male</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">standard_error</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(40.59122204599277)
</pre></div>
</div>
</div>
</div>
<p>Now let’s consider one more result we can compute with normal distributions, the distribution of differences.</p>
</section>
<section id="distribution-of-differences">
<h2>Distribution of Differences<a class="headerlink" href="#distribution-of-differences" title="Link to this heading">#</a></h2>
<p>Putting together the steps from the previous section, here’s how we can compute the distribution of sample means for the weights of the female penguins.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights_female</span><span class="p">)</span>
<span class="n">dist_mean_female</span> <span class="o">=</span> <span class="n">dist_female</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">dist_mean_female</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal(3368.835616438356, 994.0498530055667)
</pre></div>
</div>
</div>
</div>
<p>Now we have sampling distributions for the average weight of male and female penguins – let’s compute the distribution of the differences.
The following method computes the distribution of the difference between values from two normal distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def __sub__(self, other):
    &quot;&quot;&quot;Compute the distribution of a difference.&quot;&quot;&quot;
    return Normal(self.mu - other.mu, self.sigma2 + other.sigma2)
</pre></div>
</div>
</div>
</div>
<p>As you might expect, the mean of the differences is the difference of the means.
But as you might not expect, the variance of the differences is not the difference of the variances – it’s the sum!
To see why, imagine we perform subtraction in two steps:</p>
<ul class="simple">
<li><p>If we negate the second distribution, the mean is negated but the variance is the same.</p></li>
<li><p>Then if we add in the first distribution, the variance of the sum is the sum of the variances.</p></li>
</ul>
<p>If that doesn’t convince you, let’s test it.
Here’s the analytic distribution of the differences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_diff_means</span> <span class="o">=</span> <span class="n">dist_mean_male</span> <span class="o">-</span> <span class="n">dist_mean_female</span>
<span class="n">dist_diff_means</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal(674.6575342465753, 2641.697160192656)
</pre></div>
</div>
</div>
</div>
<p>And here’s a random sample of differences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_sums_female</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist_female</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
<span class="n">sample_means_female</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sample_sums_female</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">sample_diff_means</span> <span class="o">=</span> <span class="n">sample_means_male</span> <span class="o">-</span> <span class="n">sample_means_female</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows the empirical CDF of the random sample and the analytic CDF of the normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_diff_means</span><span class="o">.</span><span class="n">plot_cdf</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">sample_diff_means</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Difference in average weight (g)&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/596c267b5ce8ac93fd569603318b1d2f34e2fa6ccce9cba0b17d308d1d531d23.png" src="_images/596c267b5ce8ac93fd569603318b1d2f34e2fa6ccce9cba0b17d308d1d531d23.png" />
</div>
</div>
<p>They agree, which confirms that we found the distribution of the differences correctly.
We can use this distribution to compute a confidence interval for the difference in weights.
We’ll use the following method to compute the inverse CDF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def ppf(self, xs):
    sigma = np.sqrt(self.sigma2)
    return norm.ppf(xs, self.mu, sigma)
</pre></div>
</div>
</div>
</div>
<p>The 5th and 95th percentiles form a 90% confidence interval.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ci90</span> <span class="o">=</span> <span class="n">dist_diff_means</span><span class="o">.</span><span class="n">ppf</span><span class="p">([</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">])</span>
<span class="n">ci90</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([590.1162635 , 759.19880499])
</pre></div>
</div>
</div>
</div>
<p>We get approximately the same results from the random sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">sample_diff_means</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">95</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([578.86837628, 759.86657441])
</pre></div>
</div>
</div>
</div>
<p>The analytic method is faster than resampling, and it is deterministic – that is, not random.</p>
<p>However, everything we’ve done so far is based on the assumption that the distribution of measurements is normal.
That’s not always true – in fact, with real data it is never exactly true.
But even if the distribution of the measurements isn’t normal, if we add up many measurements, the distribution of their sum is often close to normal.
That is the power of the Central Limit Theorem.</p>
</section>
<section id="central-limit-theorem">
<span id="section-central-limit-theorem"></span><h2>Central Limit Theorem<a class="headerlink" href="#central-limit-theorem" title="Link to this heading">#</a></h2>
<p>As we saw in the previous sections, if we add values drawn from normal distributions, the distribution of the sum is normal.
Most other distributions don’t have this property – for example, if we add values drawn from an exponential distribution, the distribution of the sum is not exponential.</p>
<p>But for many distributions, if we generate <code class="docutils literal notranslate"><span class="pre">n</span></code> values and add them up, the distribution of the sum converges to normal as <code class="docutils literal notranslate"><span class="pre">n</span></code> increases.
More specifically, if the distribution of the values has mean <code class="docutils literal notranslate"><span class="pre">m</span></code> and variance <code class="docutils literal notranslate"><span class="pre">s2</span></code> the distribution of the sum converges to a normal distribution with mean <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">*</span> <span class="pre">m</span></code> and variance <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">*</span> <span class="pre">s2</span></code>.</p>
<p>That conclusion is the Central Limit Theorem (CLT).
It is one of the most useful tools for statistical analysis, but it comes with caveats:</p>
<ul class="simple">
<li><p>The values have to come from the same distribution (although this requirement can be relaxed).</p></li>
<li><p>The values have to be drawn independently. If they are correlated, the CLT doesn’t apply (although it can still work if the correlation is not too strong).</p></li>
<li><p>The values have to be drawn from a distribution with finite mean and variance. So the CLT doesn’t apply to some long-tailed distributions.</p></li>
</ul>
<p>The Central Limit Theorem explains the prevalence of normal distributions in the natural world.
Many characteristics of living things are affected by genetic and environmental factors whose effect is additive.
The characteristics we measure are the sum of a large number of small effects, so their distribution tends to be normal.</p>
<p>To see how the Central Limit Theorem works, and when it doesn’t, let’s try some experiments,
starting with an exponential distribution.
The following loop generates samples from an exponential distribution, adds them up, and makes a dictionary that maps from each sample size, <code class="docutils literal notranslate"><span class="pre">n</span></code>, to a list of 1001 sums.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lam</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">df_sample_expo</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="n">df_sample_expo</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">lam</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>Here are the averages for each list of sums.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_sample_expo</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1        0.989885
10       9.825744
100    100.022555
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>The average value from this distribution is 1, so if we add up 10 values, the average of the sum is close to 10, and if we add up 100 values the average of the sum is close to 100.</p>
<p>This function takes the <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> we just made and makes a normal probability plot for each list of sums.</p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">normal_plot_samples</span><span class="p">(</span><span class="n">df_sample</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Normal probability plots for samples of sums.&quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">6.8</span><span class="p">,</span> <span class="mf">2.6</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df_sample</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">normal_probability_plot</span><span class="p">(</span><span class="n">df_sample</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
        <span class="n">decorate</span><span class="p">(</span>
            <span class="n">title</span><span class="o">=</span><span class="s2">&quot;n=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">n</span><span class="p">,</span>
            <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span>
            <span class="n">yticks</span><span class="o">=</span><span class="p">[],</span>
            <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Standard normal&quot;</span><span class="p">,</span>
            <span class="n">ylabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows normal probability plots for the three lists of sums (the definition of <code class="docutils literal notranslate"><span class="pre">normal_plot_samples</span></code> is in the notebook for this chapter).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_plot_samples</span><span class="p">(</span><span class="n">df_sample_expo</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Sum of exponential values&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/771475bfc28457c8034dd0715e4bc6d6dcd8e75838c03bfb8a49aaa1d3c4ae23.png" src="_images/771475bfc28457c8034dd0715e4bc6d6dcd8e75838c03bfb8a49aaa1d3c4ae23.png" />
</div>
</div>
<p>When <code class="docutils literal notranslate"><span class="pre">n=1</span></code>, the distribution of the sum is exponential, so the normal probability plot is not a straight line.
But with <code class="docutils literal notranslate"><span class="pre">n=10</span></code> the distribution of the sum is approximately normal, and with <code class="docutils literal notranslate"><span class="pre">n=100</span></code> it is almost indistinguishable from normal.</p>
<p>For distributions that are less skewed than an exponential, the distribution of the sum converges to normal more quickly – that is, for smaller values of <code class="docutils literal notranslate"><span class="pre">n</span></code>.
For distributions that are more skewed, it takes longer.
As an example, let’s look at sums of values from a lognormal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">1.0</span>
<span class="n">df_sample_lognormal</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="n">df_sample_lognormal</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Here are the normal probability plots for the same range of sample sizes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_plot_samples</span><span class="p">(</span><span class="n">df_sample_lognormal</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Sum of lognormal values&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/992059cdf6c2ff8c2aefa522b20aed972f30ffed9f8a5c38f86104666289e8fd.png" src="_images/992059cdf6c2ff8c2aefa522b20aed972f30ffed9f8a5c38f86104666289e8fd.png" />
</div>
</div>
<p>When <code class="docutils literal notranslate"><span class="pre">n=1</span></code>, a normal model does not fit the distribution, and it is not much better with <code class="docutils literal notranslate"><span class="pre">n=10</span></code>.
Even with <code class="docutils literal notranslate"><span class="pre">n=100</span></code>, the tails of the distribution clearly deviate from the model.</p>
<p>The mean and variance of the lognormal distribution are finite, so the distribution of the sum converges to normal eventually.
But for some highly skewed distributions, it might not converge at any practical sample size.
And in some cases, it doesn’t happen at all.</p>
</section>
<section id="the-limits-of-the-central-limit-theorem">
<h2>The Limits of the Central Limit Theorem<a class="headerlink" href="#the-limits-of-the-central-limit-theorem" title="Link to this heading">#</a></h2>
<p>Pareto distributions are even more skewed than lognormal.
Depending on the parameters, some Pareto distributions do not have finite mean and variance – in those cases, the Central Limit Theorem does not apply.</p>
<p>To demonstrate, we’ll generate values from a Pareto distribution with parameter <code class="docutils literal notranslate"><span class="pre">alpha=1</span></code>, which has infinite mean and variance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">df_sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="n">df_sample</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">pareto</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s what the normal probability plots look like for a range of sample sizes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_plot_samples</span><span class="p">(</span><span class="n">df_sample</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Sum of Pareto values&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/587b9641385d2eb3b402badb3ed3172d2a45694e547a64cf0a6f2c63806aac36.png" src="_images/587b9641385d2eb3b402badb3ed3172d2a45694e547a64cf0a6f2c63806aac36.png" />
</div>
</div>
<p>Even with <code class="docutils literal notranslate"><span class="pre">n=100</span></code>, the distribution of the sum is nothing like a normal distribution.</p>
<p>I also mentioned that the CLT does not apply if the values are correlated.
To test that, we’ll use a function called <code class="docutils literal notranslate"><span class="pre">generate_expo_correlated</span></code> to generate values from an exponential distribution where the serial correlation – that is, the correlation between successive elements in the sample – is the given value, <code class="docutils literal notranslate"><span class="pre">rho</span></code>.
This function is defined in the notebook for this chapter.</p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_normal_correlated</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates an array of correlated values from a standard normal dist.&quot;&quot;&quot;</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">xs</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">xs</span>
</pre></div>
</div>
</div>
</div>
<p>Given a correlated sequence from a normal distribution, the following function generates a correlated sequence from an exponential distribution.</p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">expon</span>


<span class="k">def</span><span class="w"> </span><span class="nf">generate_expo_correlated</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates a sequence of correlated values from an exponential dist.&quot;&quot;&quot;</span>
    <span class="n">normal</span> <span class="o">=</span> <span class="n">generate_normal_correlated</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">rho</span><span class="p">)</span>
    <span class="n">uniform</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">normal</span><span class="p">)</span>
    <span class="n">expo</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">uniform</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">expo</span>
</pre></div>
</div>
</div>
</div>
<p>It starts with a sequence of correlated normal values and uses the normal CDF to transform them to a sequence of values from a uniform distribution between 0 and 1.
Then it uses the exponential inverse CDF to transform them to a sequence of exponential values.</p>
<p>The following loop makes a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with one column for each sample size and 1001 sums in each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">df_sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="n">df_sample</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">generate_expo_correlated</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">rho</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>Here are the normal probability plots for the distribution of these sums.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">normal_plot_samples</span><span class="p">(</span><span class="n">df_sample</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Sum of correlated values&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/14c589bb074224b2acca7b61ea39e860ba0bd6970265d02e1629e183da8b0519.png" src="_images/14c589bb074224b2acca7b61ea39e860ba0bd6970265d02e1629e183da8b0519.png" />
</div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">rho=0.8</span></code>, there is a strong correlation between successive elements, and the distribution of the sum converges slowly.
If there is also a strong correlation between distant elements of the sequence, it might not converge at all.</p>
<p>The previous section shows that the Central Limit Theorem works, and this section shows what happens when it doesn’t.
Now let’s see how we can use it.</p>
</section>
<section id="applying-the-clt">
<h2>Applying the CLT<a class="headerlink" href="#applying-the-clt" title="Link to this heading">#</a></h2>
<p>To see why the Central Limit Theorem is useful, let’s get back to the example in <a class="reference internal" href="chap09.html#section-diff-means"><span class="std std-ref">Chapter 9</span></a>: testing the apparent difference in mean pregnancy length for first babies and others.
We’ll use the NSFG data again – instructions for downloading it are in the notebook for this chapter.</p>
<p>The following cell downloads the data.</p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/nb/nsfg.py&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dct&quot;</span><span class="p">)</span>
<span class="n">download</span><span class="p">(</span><span class="s2">&quot;https://github.com/AllenDowney/ThinkStats/raw/v3/data/2002FemPreg.dat.gz&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We’ll use <code class="docutils literal notranslate"><span class="pre">get_nsfg_groups</span></code> to read the data and divide it into first babies and others.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nsfg</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_nsfg_groups</span>

<span class="n">live</span><span class="p">,</span> <span class="n">firsts</span><span class="p">,</span> <span class="n">others</span> <span class="o">=</span> <span class="n">get_nsfg_groups</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>As we’ve seen, first babies are born a little later, on average – the apparent difference is about 0.078 weeks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">delta</span> <span class="o">=</span> <span class="n">firsts</span><span class="p">[</span><span class="s2">&quot;prglngth&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">others</span><span class="p">[</span><span class="s2">&quot;prglngth&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">delta</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.07803726677754952)
</pre></div>
</div>
</div>
</div>
<p>To see whether this difference might have happened by chance, we’ll assume as a null hypothesis that the mean and variance of pregnancy lengths is actually the same for both groups, so we can estimate it using all live births.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">all_lengths</span> <span class="o">=</span> <span class="n">live</span><span class="p">[</span><span class="s2">&quot;prglngth&quot;</span><span class="p">]</span>
<span class="n">m</span><span class="p">,</span> <span class="n">s2</span> <span class="o">=</span> <span class="n">all_lengths</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">all_lengths</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The distribution of pregnancy lengths does not follow a normal distribution – nevertheless, we can use a normal distribution to approximate the sampling distribution of the mean.</p>
<p>The following function takes a sequence of values and returns a <code class="docutils literal notranslate"><span class="pre">Normal</span></code> object that represents the sampling distribution of the mean of a sample with the given size, <code class="docutils literal notranslate"><span class="pre">n</span></code>, drawn from a normal distribution with the same mean and variance as the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sampling_dist_mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">var</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s a normal approximation to the sampling distribution of mean weight for first births, under the null hypothesis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n1</span> <span class="o">=</span> <span class="n">firsts</span><span class="p">[</span><span class="s2">&quot;totalwgt_lb&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">dist_firsts</span> <span class="o">=</span> <span class="n">sampling_dist_mean</span><span class="p">(</span><span class="n">all_lengths</span><span class="p">,</span> <span class="n">n1</span><span class="p">)</span>
<span class="n">n1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.int64(4363)
</pre></div>
</div>
</div>
</div>
<p>And here’s the sampling distribution for other babies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n2</span> <span class="o">=</span> <span class="n">others</span><span class="p">[</span><span class="s2">&quot;totalwgt_lb&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">dist_others</span> <span class="o">=</span> <span class="n">sampling_dist_mean</span><span class="p">(</span><span class="n">all_lengths</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
<span class="n">n2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.int64(4675)
</pre></div>
</div>
</div>
</div>
<p>We can compute the sampling distribution of the difference like this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_diff</span> <span class="o">=</span> <span class="n">dist_firsts</span> <span class="o">-</span> <span class="n">dist_others</span>
<span class="n">dist_diff</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal(0.0, 0.003235837567930557)
</pre></div>
</div>
</div>
</div>
<p>The mean is 0, which makes sense because if we draw two samples from the same distribution, we expect the difference in means to be 0, on average.
The variance of the sampling distribution is 0.0032, which indicates how much variation we expect in the difference due to chance.</p>
<p>To confirm that this distribution approximates the sampling distribution, we can also estimate it by resampling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_firsts</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">all_lengths</span><span class="p">,</span> <span class="n">n1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
<span class="n">sample_others</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">all_lengths</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
<span class="n">sample_diffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">sample_firsts</span><span class="p">,</span> <span class="n">sample_others</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the empirical CDF of the resampled differences compared to the normal model.
The vertical dotted lines show the observed difference, positive and negative.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist_diff</span><span class="o">.</span><span class="n">plot_cdf</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">sample_diffs</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="n">delta</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Difference in pregnancy length&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8554f3cc4200ae56cb83ba2865c3fa27e114ce327b2076f6c9c7e765e5bc586d.png" src="_images/8554f3cc4200ae56cb83ba2865c3fa27e114ce327b2076f6c9c7e765e5bc586d.png" />
</div>
</div>
<p>In this example, the sample sizes are large and the skewness of the measurements is modest, so the sampling distribution is well approximated by a normal distribution.
Therefore, we can use the normal CDF to compute a p-value.
The following method computes the CDF of a normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">add_method_to</span> Normal


def cdf(self, xs):
    sigma = np.sqrt(self.sigma2)
    return norm.cdf(xs, self.mu, sigma)
</pre></div>
</div>
</div>
</div>
<p>Here’s the probability of a difference as large as <code class="docutils literal notranslate"><span class="pre">delta</span></code> under the null hypothesis, which is the area under the right tail of the sampling distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">right</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dist_diff</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span>
<span class="n">right</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.08505405315526993)
</pre></div>
</div>
</div>
</div>
<p>And here’s the probability of a difference as negative as <code class="docutils literal notranslate"><span class="pre">-delta</span></code>, which is the area under the left tail.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">left</span> <span class="o">=</span> <span class="n">dist_diff</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="n">delta</span><span class="p">)</span>
<span class="n">left</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.08505405315526993)
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">left</span></code> and <code class="docutils literal notranslate"><span class="pre">right</span></code> are the same because the normal distribution is symmetric.
The sum of the two is the probability of a difference as large as <code class="docutils literal notranslate"><span class="pre">delta</span></code>, positive or negative.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.17010810631053985)
</pre></div>
</div>
</div>
</div>
<p>The resulting p-value is 0.170, which is consistent with the estimate we computed by resampling in <a class="reference internal" href="chap09.html#section-diff-means"><span class="std std-ref">Chapter 9</span></a>.</p>
<p>The way we computed this p-value is similar to an <strong>independent sample <span class="math notranslate nohighlight">\(t\)</span> test</strong>.
SciPy provides a function called <code class="docutils literal notranslate"><span class="pre">ttest_ind</span></code> that takes two samples and computes a p-value for the difference in their means.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span><span class="n">firsts</span><span class="p">[</span><span class="s2">&quot;prglngth&quot;</span><span class="p">],</span> <span class="n">others</span><span class="p">[</span><span class="s2">&quot;prglngth&quot;</span><span class="p">])</span>
<span class="n">result</span><span class="o">.</span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.16755412639415004)
</pre></div>
</div>
</div>
</div>
<p>When the sample sizes are large, the result of the <span class="math notranslate nohighlight">\(t\)</span> test is close to what we computed with normal distributions.
The <span class="math notranslate nohighlight">\(t\)</span> test is so called because it is based on a <strong>t distribution</strong> rather than a normal distribution.
The <span class="math notranslate nohighlight">\(t\)</span> distribution is also useful for testing whether a correlation is statistically significant, as we’ll see in the next section.</p>
</section>
<section id="correlation-test">
<h2>Correlation Test<a class="headerlink" href="#correlation-test" title="Link to this heading">#</a></h2>
<p>In <a class="reference internal" href="chap09.html#section-test-correlation"><span class="std std-ref">Chapter 9</span></a> we used a permutation test for the correlation between birth weight and mother’s age, and found that it is statistically significant, with p-value less than 0.001.</p>
<p>Now we can do the same thing analytically.
The method is based on this mathematical result: If we generate two samples with size <code class="docutils literal notranslate"><span class="pre">n</span></code> from normal distributions, compute Pearson’s correlation, <code class="docutils literal notranslate"><span class="pre">r</span></code>, and then transform the correlation with this function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">transform_correlation</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">r</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The transformed correlations follow a <span class="math notranslate nohighlight">\(t\)</span> distribution with parameter <code class="docutils literal notranslate"><span class="pre">n-2</span></code>.
To see what that looks like, we’ll use the following function to generate uncorrelated samples from a standard normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_data</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Uncorrelated sequences from a standard normal.&quot;&quot;&quot;</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span>
</pre></div>
</div>
</div>
</div>
<p>And the following function to compute their correlation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">correlation</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="n">data</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>The following loop generates many pairs of samples, computes their correlation, and puts the results in a list.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">rs</span> <span class="o">=</span> <span class="p">[</span><span class="n">correlation</span><span class="p">(</span><span class="n">generate_data</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>Next we’ll compute the transformed correlations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span> <span class="o">=</span> <span class="n">transform_correlation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rs</span><span class="p">),</span> <span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To check whether these <code class="docutils literal notranslate"><span class="pre">ts</span></code> follow a <span class="math notranslate nohighlight">\(t\)</span> distribution, we’ll use the following function, which makes an object that represents the CDF of a <span class="math notranslate nohighlight">\(t\)</span> distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">t</span> <span class="k">as</span> <span class="n">student_t</span>


<span class="k">def</span><span class="w"> </span><span class="nf">make_student_cdf</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the CDF of a Student t distribution.&quot;&quot;&quot;</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">student_t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Cdf</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">ts</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The parameter of the <span class="math notranslate nohighlight">\(t\)</span> distribution is called <code class="docutils literal notranslate"><span class="pre">df</span></code>, which stands for “degrees of freedom”.
The following figure shows the CDF of a <span class="math notranslate nohighlight">\(t\)</span> distribution with parameter <code class="docutils literal notranslate"><span class="pre">n-2</span></code> along with the empirical CDF of the transformed correlations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">make_student_cdf</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>

<span class="n">cdf_ts</span> <span class="o">=</span> <span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>
<span class="n">cdf_ts</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;random normals&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Transformed correlation&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3f882ea0aeae5d9714d9e5958377a90cb38f09ce078584497fec4ff0d9b2223a.png" src="_images/3f882ea0aeae5d9714d9e5958377a90cb38f09ce078584497fec4ff0d9b2223a.png" />
</div>
</div>
<p>This shows that if we draw uncorrelated samples from normal distributions, their transformed correlations follow a <span class="math notranslate nohighlight">\(t\)</span> distribution.</p>
<p>If we draw samples from other distributions, their transformed correlations don’t follow a <span class="math notranslate nohighlight">\(t\)</span> distribution exactly, but they converge to a <span class="math notranslate nohighlight">\(t\)</span> distribution as the sample size increases.
Let’s see if this applies to the correlation of maternal age and birth weight.
From the <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> of live births, we’ll select the rows with valid data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;agepreg&quot;</span><span class="p">,</span> <span class="s2">&quot;totalwgt_lb&quot;</span><span class="p">])</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
<span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>9038
</pre></div>
</div>
</div>
</div>
<p>The actual correlation is about 0.07.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="s2">&quot;agepreg&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">valid</span><span class="p">[</span><span class="s2">&quot;totalwgt_lb&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">r_actual</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">r_actual</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.0688339703541091)
</pre></div>
</div>
</div>
</div>
<p>As we did in <a class="reference internal" href="chap09.html#section-test-correlation"><span class="std std-ref">Chapter 9</span></a>, we can simulate the null hypothesis by permuting the samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">permute</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Shuffle the x values.&quot;&quot;&quot;</span>
    <span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">new_xs</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">new_xs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_xs</span><span class="p">,</span> <span class="n">ys</span>
</pre></div>
</div>
</div>
</div>
<p>If we generate many permutations and compute their correlations, the result is a sample from the distribution of correlations under the null hypothesis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">permuted_corrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">correlation</span><span class="p">(</span><span class="n">permute</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>And we can compute the transformed correlations like this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts</span> <span class="o">=</span> <span class="n">transform_correlation</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">permuted_corrs</span><span class="p">),</span> <span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The following figure shows the empirical CDF of the <code class="docutils literal notranslate"><span class="pre">ts</span></code> along with the CDF of the <span class="math notranslate nohighlight">\(t\)</span> distribution with parameter <code class="docutils literal notranslate"><span class="pre">n-2</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">make_student_cdf</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;permuted data&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Transformed correlation&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/969c27dc5ddcfb66a7f3f7217e0c8e179ef642cbac9a8808c75b787e31aae984.png" src="_images/969c27dc5ddcfb66a7f3f7217e0c8e179ef642cbac9a8808c75b787e31aae984.png" />
</div>
</div>
<p>The model fits the empirical distribution well, which means we can use it to compute a p-value for the observed correlation.
First we’ll transform the observed correlation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_actual</span> <span class="o">=</span> <span class="n">transform_correlation</span><span class="p">(</span><span class="n">r_actual</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can use the CDF of the <span class="math notranslate nohighlight">\(t\)</span> distribution to compute the probability of a value as large as <code class="docutils literal notranslate"><span class="pre">t_actual</span></code> under the null hypothesis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">right</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">student_t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">t_actual</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">right</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(2.861466619208386e-11)
</pre></div>
</div>
</div>
</div>
<p>We can also compute the probability of a value as negative as <code class="docutils literal notranslate"><span class="pre">-t_actual</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">left</span> <span class="o">=</span> <span class="n">student_t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="n">t_actual</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">left</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(2.8614735536574016e-11)
</pre></div>
</div>
</div>
</div>
<p>The sum of the two is the probability of a correlation as big as <code class="docutils literal notranslate"><span class="pre">r_actual</span></code>, positive or negative.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">left</span> <span class="o">+</span> <span class="n">right</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(5.722940172865787e-11)
</pre></div>
</div>
</div>
</div>
<p>SciPy provides a function that does the same calculation and returns the p-value of the observed correlation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">pearsonr</span>

<span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>
<span class="n">p_value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(5.7229471073151754e-11)
</pre></div>
</div>
</div>
</div>
<p>The results are nearly the same.</p>
<p>Based on the resampling results, we concluded that the p-value was less than 0.001, but we could not say how much less without running a very large number of resamplings.
With analytic methods, we can compute small p-values quickly.</p>
<p>However, in practice it might not matter.
Generally, if a p-value is smaller than 0.001, we can conclude that the observed effect is unlikely to be due to chance.
It is not usually important to know precisely how unlikely.</p>
</section>
<section id="chi-squared-test">
<h2>Chi-squared Test<a class="headerlink" href="#chi-squared-test" title="Link to this heading">#</a></h2>
<p>In <a class="reference internal" href="chap09.html#section-testing-proportions"><span class="std std-ref">Chapter 9</span></a> we tested whether a die is crooked, based on this set of observed outcomes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">empiricaldist</span><span class="w"> </span><span class="kn">import</span> <span class="n">Hist</span>

<span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">freqs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">11</span><span class="p">]</span>
<span class="n">observed</span> <span class="o">=</span> <span class="n">Hist</span><span class="p">(</span><span class="n">freqs</span><span class="p">,</span> <span class="n">qs</span><span class="p">)</span>
<span class="n">observed</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;outcome&quot;</span>
<span class="n">observed</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>freqs</th>
    </tr>
    <tr>
      <th>outcome</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
    </tr>
    <tr>
      <th>5</th>
      <td>8</td>
    </tr>
    <tr>
      <th>6</th>
      <td>11</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>First we computed the expected frequency for each outcome.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_rolls</span> <span class="o">=</span> <span class="n">observed</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="n">observed</span><span class="o">.</span><span class="n">qs</span>
<span class="n">expected</span> <span class="o">=</span> <span class="n">Hist</span><span class="p">(</span><span class="n">num_rolls</span> <span class="o">/</span> <span class="mi">6</span><span class="p">,</span> <span class="n">outcomes</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we used the following function to compute the chi-squared statistic.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">chi_squared_stat</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">expected</span><span class="p">):</span>
    <span class="n">diffs</span> <span class="o">=</span> <span class="p">(</span><span class="n">observed</span> <span class="o">-</span> <span class="n">expected</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">ratios</span> <span class="o">=</span> <span class="n">diffs</span> <span class="o">/</span> <span class="n">expected</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ratios</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observed_chi2</span> <span class="o">=</span> <span class="n">chi_squared_stat</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The chi-squared statistic is widely used for this kind of data because its sampling distribution under the null hypothesis converges to a distribution we can compute efficiently – not coincidentally, it is called a <strong>chi-squared distribution</strong>.
To see what it looks like, we’ll use the following function, which simulates rolling a fair die.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">simulate_dice</span><span class="p">(</span><span class="n">observed</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
    <span class="n">rolls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">observed</span><span class="o">.</span><span class="n">qs</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">hist</span> <span class="o">=</span> <span class="n">Hist</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">rolls</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hist</span>
</pre></div>
</div>
</div>
</div>
<p>The following loop runs the simulation many times and computes the chi-squared statistic of the outcomes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulated_chi_squared</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">chi_squared_stat</span><span class="p">(</span><span class="n">simulate_dice</span><span class="p">(</span><span class="n">observed</span><span class="p">),</span> <span class="n">expected</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1001</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">cdf_simulated</span> <span class="o">=</span> <span class="n">Cdf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">simulated_chi_squared</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To check whether the results follow a chi-squared distribution, we’ll use the following function, which computes the CDF of a chi-squared distribution with parameter <code class="docutils literal notranslate"><span class="pre">df</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">chi2</span> <span class="k">as</span> <span class="n">chi2_dist</span>


<span class="k">def</span><span class="w"> </span><span class="nf">chi_squared_cdf</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Discrete approximation of the chi-squared CDF.&quot;&quot;&quot;</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">chi2_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Cdf</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">n</span></code> possible outcomes, the simulated chi-squared statistics should follow a chi-squared distribution with parameter <code class="docutils literal notranslate"><span class="pre">n-1</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
<span class="n">cdf_model</span> <span class="o">=</span> <span class="n">chi_squared_cdf</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s the empirical CDF of the simulated chi-squared statistics along with the CDF of the chi-squared distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cdf_model</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">model_options</span><span class="p">)</span>
<span class="n">cdf_simulated</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;simulation&quot;</span><span class="p">)</span>

<span class="n">decorate</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Chi-squared statistic&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;CDF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/14da013801f82e99c9c52b754fea106deff44e8452ea419fe232db08895628f6.png" src="_images/14da013801f82e99c9c52b754fea106deff44e8452ea419fe232db08895628f6.png" />
</div>
</div>
<p>The model fits the simulation results well, so we can use it to compute the probability of a value as large as <code class="docutils literal notranslate"><span class="pre">observed_chi2</span></code> under the null hypothesis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">chi2_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">observed_chi2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">p_value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.04069938850404997)
</pre></div>
</div>
</div>
</div>
<p>SciPy provides a function that does the same computation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">chisquare</span>

<span class="n">chi2_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">chisquare</span><span class="p">(</span><span class="n">f_obs</span><span class="o">=</span><span class="n">observed</span><span class="p">,</span> <span class="n">f_exp</span><span class="o">=</span><span class="n">expected</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The result is the same as the p-value we computed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p_value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.040699388504049985)
</pre></div>
</div>
</div>
</div>
<p>The advantage of the chi-squared statistic is that its distribution under the null hypothesis can be computed efficiently.
But in context, it might not be the statistic that best quantifies the difference between the observed and expected outcomes.</p>
</section>
<section id="computation-and-analysis">
<h2>Computation and Analysis<a class="headerlink" href="#computation-and-analysis" title="Link to this heading">#</a></h2>
<p>This book focuses on computational methods like resampling and permutation.
These methods have several advantages over analysis:</p>
<ul class="simple">
<li><p>They are easier to explain and understand. For example, one of the most difficult topics in an introductory statistics class is hypothesis testing. Many students don’t really understand what p-values are. I think the approach we took in <a class="reference internal" href="chap09.html#chapter-hypothesis-testing"><span class="std std-ref">Chapter 9</span></a> – simulating the null hypothesis and computing test statistics – makes the fundamental idea clearer.</p></li>
<li><p>They are robust and versatile. Analytic methods are often based on assumptions that don’t hold in practice. Computational methods require fewer assumptions, and can be adapted and extended more easily.</p></li>
<li><p>They are debuggable. Analytic methods are often like a black box: you plug in numbers and they spit out results. But it’s easy to make subtle errors, hard to be confident that the results are right, and hard to diagnose the problem if they are not. Computational methods lend themselves to incremental development and testing, which fosters confidence in the results.</p></li>
</ul>
<p>But there are drawbacks:</p>
<ul class="simple">
<li><p>Computational methods can be slow.</p></li>
<li><p>Randomized methods like resampling don’t produce the same results every time, which makes it harder to check that they are correct.</p></li>
</ul>
<p>Taking into account these pros and cons, I recommend the following process:</p>
<ol class="arabic simple">
<li><p>Use computational methods during exploration. If you find a satisfactory answer and the run time is acceptable, you can stop.</p></li>
<li><p>If run time is not acceptable, look for opportunities to optimize. Using analytic methods is one of several methods of optimization.</p></li>
<li><p>If replacing a computational method with an analytic method is appropriate, use the computational method as a basis of comparison, providing mutual validation between the computational and analytic results.</p></li>
</ol>
<p>For many practical problems, the run time of computational methods is not a problem, and we don’t have to go past the first step.</p>
</section>
<section id="glossary">
<h2>Glossary<a class="headerlink" href="#glossary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>normal probability plot:</strong> A plot that compares observed values with the quantiles of a normal distribution to see how closely the data follow a normal distribution.</p></li>
<li><p><strong>independent sample <span class="math notranslate nohighlight">\(t\)</span> test:</strong> A method for computing the p-value of an observed difference between the means of two independent groups.</p></li>
<li><p><strong><span class="math notranslate nohighlight">\(t\)</span> distribution:</strong> A distribution used to model the sampling distribution of a difference in means under the null hypothesis that the difference is 0, as well as the sampling distribution of transformed correlations.</p></li>
<li><p><strong>chi-squared distribution:</strong> A distribution used to model the sampling distribution of the chi-squared statistic.</p></li>
<li><p><strong>chi-squared statistic:</strong> A test statistic that quantifies the magnitude of the difference between two discrete distributions.</p></li>
</ul>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<section id="exercise-14-1">
<h3>Exercise 14.1<a class="headerlink" href="#exercise-14-1" title="Link to this heading">#</a></h3>
<p>In this chapter we compared the weights of male and female penguins and computed a confidence interval for the difference.
Now let’s do the same for flipper length.
The observed difference is about 4.6 mm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grouped</span> <span class="o">=</span> <span class="n">adelie</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Sex&quot;</span><span class="p">)</span>

<span class="n">lengths_male</span> <span class="o">=</span> <span class="n">grouped</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;MALE&quot;</span><span class="p">)[</span><span class="s2">&quot;Flipper Length (mm)&quot;</span><span class="p">]</span>
<span class="n">lengths_female</span> <span class="o">=</span> <span class="n">grouped</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;FEMALE&quot;</span><span class="p">)[</span><span class="s2">&quot;Flipper Length (mm)&quot;</span><span class="p">]</span>
<span class="n">observed_diff</span> <span class="o">=</span> <span class="n">lengths_male</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">lengths_female</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">observed_diff</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(4.616438356164366)
</pre></div>
</div>
</div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">sampling_dist_mean</span></code> to make <code class="docutils literal notranslate"><span class="pre">Normal</span></code> objects that represent sampling distributions for the mean flipper length in the two groups – noting that the groups are not the same size.
Then compute the sampling distribution of the difference and a 90% confidence interval.</p>
</section>
<section id="exercise-14-2">
<h3>Exercise 14.2<a class="headerlink" href="#exercise-14-2" title="Link to this heading">#</a></h3>
<p>Using the NSFG data, we computed the correlation between a baby’s birth weight and the mother’s age, and we used a <span class="math notranslate nohighlight">\(t\)</span> distribution to compute a p-value.
Now let’s do the same with birth weight and father’s age, which is recorded in the <code class="docutils literal notranslate"><span class="pre">hpagelb</span></code> column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;hpagelb&quot;</span><span class="p">,</span> <span class="s2">&quot;totalwgt_lb&quot;</span><span class="p">])</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
<span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8933
</pre></div>
</div>
</div>
</div>
<p>The observed correlation is about 0.065.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="s2">&quot;hpagelb&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">valid</span><span class="p">[</span><span class="s2">&quot;totalwgt_lb&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">r_actual</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">r_actual</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.06468629895432174)
</pre></div>
</div>
</div>
</div>
<p>Compute the transformed correlation, <code class="docutils literal notranslate"><span class="pre">t_actual</span></code>.
Use the CDF of the <span class="math notranslate nohighlight">\(t\)</span> distribution to compute a p-value – is this correlation statistically significant?
Use the SciPy function <code class="docutils literal notranslate"><span class="pre">pearsonr</span></code> to check your results.</p>
</section>
<section id="exercise-14-3">
<h3>Exercise 14.3<a class="headerlink" href="#exercise-14-3" title="Link to this heading">#</a></h3>
<p>In one of the exercises in <a class="reference internal" href="chap09.html#chapter-hypothesis-testing"><span class="std std-ref">Chapter 9</span></a> we considered the Trivers-Willard hypothesis, which suggests that for many mammals the sex ratio depends on “maternal condition” – that is, factors like the mother’s age, size, health, and social status.
Some studies have shown this effect among humans, but results are mixed.</p>
<p>As an example, and a chance to practice a chi-squared test, let’s see if there’s a relationship between the sex of a baby and the mother’s marital status.
The notebook for this chapter has instructions to help you get started.</p>
<p>First we’ll partition mothers of male and female babies.</p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">male</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;babysex == 1&quot;</span><span class="p">)</span>
<span class="n">female</span> <span class="o">=</span> <span class="n">live</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;babysex == 2&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we’ll make a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with one column for each group and one row for each value of <code class="docutils literal notranslate"><span class="pre">fmarital</span></code>, which encodes marital status like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span>  <span class="n">married</span>
<span class="mi">2</span>  <span class="n">widowed</span>
<span class="mi">3</span>  <span class="n">divorces</span>
<span class="mi">4</span>  <span class="n">separated</span>
<span class="mi">5</span>  <span class="n">never</span> <span class="n">married</span>
</pre></div>
</div>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">observed</span><span class="p">[</span><span class="s2">&quot;male&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">male</span><span class="p">[</span><span class="s2">&quot;fmarital&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="n">observed</span><span class="p">[</span><span class="s2">&quot;female&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">female</span><span class="p">[</span><span class="s2">&quot;fmarital&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="n">observed</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>male</th>
      <th>female</th>
    </tr>
    <tr>
      <th>fmarital</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2576</td>
      <td>2559</td>
    </tr>
    <tr>
      <th>2</th>
      <td>56</td>
      <td>54</td>
    </tr>
    <tr>
      <th>3</th>
      <td>568</td>
      <td>572</td>
    </tr>
    <tr>
      <th>4</th>
      <td>355</td>
      <td>330</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1086</td>
      <td>985</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The null hypothesis is that the distribution of marital status is the same for both groups, so we can use the whole dataset to compute it.</p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">empiricaldist</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pmf</span>

<span class="n">pmf_fmarital</span> <span class="o">=</span> <span class="n">Pmf</span><span class="o">.</span><span class="n">from_seq</span><span class="p">(</span><span class="n">live</span><span class="p">[</span><span class="s2">&quot;fmarital&quot;</span><span class="p">])</span>
<span class="n">pmf_fmarital</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>probs</th>
    </tr>
    <tr>
      <th>fmarital</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.561653</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.012024</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.124617</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.075208</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.226498</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>To compute the expected values, we multiply the probabilities in <code class="docutils literal notranslate"><span class="pre">pmf_marital</span></code> by the total number of cases in each column.</p>
<div class="cell tag_remove-print docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">expected</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">expected</span><span class="p">[</span><span class="s2">&quot;male&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmf_fmarital</span> <span class="o">*</span> <span class="n">observed</span><span class="p">[</span><span class="s2">&quot;male&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">expected</span><span class="p">[</span><span class="s2">&quot;female&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pmf_fmarital</span> <span class="o">*</span> <span class="n">observed</span><span class="p">[</span><span class="s2">&quot;female&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">expected</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>male</th>
      <th>female</th>
    </tr>
    <tr>
      <th>fmarital</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2606.630739</td>
      <td>2527.437691</td>
    </tr>
    <tr>
      <th>2</th>
      <td>55.805641</td>
      <td>54.110188</td>
    </tr>
    <tr>
      <th>3</th>
      <td>578.349366</td>
      <td>560.778312</td>
    </tr>
    <tr>
      <th>4</th>
      <td>349.038916</td>
      <td>338.434631</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1051.175339</td>
      <td>1019.239178</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">observed</span></code> and <code class="docutils literal notranslate"><span class="pre">expected</span></code> to compute a chi-squared statistic.
Then use the CDF of the chi-squared distribution to compute a p-value.
The degrees of freedom should be <code class="docutils literal notranslate"><span class="pre">n-1</span></code>, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of values in the observed <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.
Then use the SciPy function <code class="docutils literal notranslate"><span class="pre">chisquared</span></code> to compute the chi-squared statistic and p-value.
Hint: use the argument <code class="docutils literal notranslate"><span class="pre">axis=None</span></code> to treat the entire <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> as a single test rather than one test for each column.</p>
<p>Does this test provide support for the Trivers-Willard hypothesis?</p>
</section>
<section id="exercise-14-4">
<h3>Exercise 14.4<a class="headerlink" href="#exercise-14-4" title="Link to this heading">#</a></h3>
<p>The method we used in this chapter to analyze differences between groups can be extended to analyze “differences in differences”, which is a common experimental design.
As an example, we’ll use data from a 2014 paper that investigates the effects of an intervention intended to mitigate gender-stereotypical task allocation within student engineering teams.</p>
<p>Stein, L. A., Aragon, D., Moreno, D., &amp; Goodman, J. (2014, October). Evidence for the persistent effects of an intervention to mitigate gender-stereotypical task allocation within student engineering teams. In <em>2014 IEEE Frontiers in Education Conference (FIE) Proceedings</em> (pp. 1-9). IEEE.</p>
<p>Available from <a class="reference external" href="http://ieeexplore.ieee.org/document/7044435/">http://ieeexplore.ieee.org/document/7044435/</a>.</p>
<p>Before and after the intervention, students responded to a survey that asked them to rate their contribution to each aspect of class projects on a 7-point scale.</p>
<p>Before the intervention, male students reported higher scores for the programming aspect of the projects than female students: men reported an average score of 3.57 with standard error 0.28; women reported an average score of 1.91 with standard error 0.32.</p>
<p>After the intervention, the gender gap was smaller: the average score for men was 3.44 (SE 0.16); the average score for women was 3.18 (SE 0.16).</p>
<ol class="arabic simple">
<li><p>Make four <code class="docutils literal notranslate"><span class="pre">Normal</span></code> objects to represent the sampling distributions of the estimated means before and after the intervention, for both male and female students. Because we have standard errors for the estimated means, we don’t need to know the sample size to get the parameters of the sampling distributions.</p></li>
<li><p>Compute the sampling distributions of the gender gap – the difference in means – before and after the intervention.</p></li>
<li><p>Then compute the sampling distribution of the difference in differences – that is, the change in the size of the gap. Compute a 95% confidence interval and a p-value.</p></li>
</ol>
<p>Is there evidence that the size of the gender gap decreased after the intervention?</p>
<p><a class="reference external" href="https://allendowney.github.io/ThinkStats/index.html">Think Stats: Exploratory Data Analysis in Python, 3rd Edition</a></p>
<p>Copyright 2024 <a class="reference external" href="https://allendowney.com">Allen B. Downey</a></p>
<p>Code license: <a class="reference external" href="https://mit-license.org/">MIT License</a></p>
<p>Text license: <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="chap13.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Survival analysis</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normal-probability-plots">Normal Probability Plots</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#normal-distributions">Normal Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-of-sample-means">Distribution of Sample Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#distribution-of-differences">Distribution of Differences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#central-limit-theorem">Central Limit Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-limits-of-the-central-limit-theorem">The Limits of the Central Limit Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applying-the-clt">Applying the CLT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-test">Correlation Test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chi-squared-test">Chi-squared Test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computation-and-analysis">Computation and Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glossary">Glossary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-1">Exercise 14.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-2">Exercise 14.2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-3">Exercise 14.3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-14-4">Exercise 14.4</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Allen B. Downey
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>